input {
    file {
        path => ["C:\Users\sg30983\Desktop\LogstashConfig\jenkinslog\jenkin3.log"]
	    start_position => "beginning"
        sincedb_path => "NULL"
    }
}
filter {
    grok {
        patterns_dir => ["C:\Users\sg30983\Desktop\LogstashConfig\ELK_stack\ELK_stack\patterns"]
        patterns_files_glob => "*"
		match => { "message" => "%{TIME:time} \[%{TESTNAME:testname}\] %{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:level} - %{MODULENAME:moduleName}::%{WORD:funcName} - %{GREEDYDATA:logMessage}" }
        
        match => { "message" => "%{TIME:time} \[%{TESTNAME:testname}\] %{OTHERDATA:other}" }

        match => { "message" => "\[%{PIPELINE}\] \[%{TESTNAME:testname}\] %{PIPELINEDATA:pipelinedata}" }
    }
    
    if [level] =~ "." {
        mutate { replace => {"type" => "aftFormattedlog"} }
    } else if [other] =~ "." {
        mutate { replace => {"type" => "aftUnformattedlog"} }
    } else if [pipelinedata] =~ "." {
        if "{" in [pipelinedata] or "}" in [pipelinedata] {
            drop {}
        } else {
            mutate { replace => {"type" => "pipelinelog"} }
        }
    }

    mutate { 
        remove_field => ["[@version]", "[geoip][ip]", "[geoip][latitude]", "[geoip][location]", "[geoip][longitude]"]
    }

    if "_grokparsefailure" in [tags] {
        drop {}
    }
}
output {
    elasticsearch {
		hosts => "127.0.0.1:9200"
    }
    stdout { }
}